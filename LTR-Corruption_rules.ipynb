{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e78ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read the file\n",
    "def corruptables(jsonfile):\n",
    "    to_corrupt = []\n",
    "    with open(jsonfile) as f:\n",
    "        out = [(x) for x in json.load(f)]\n",
    "        for o in out:\n",
    "            coco = []\n",
    "            for oo in o:\n",
    "                ooo = (oo[0], oo[1])\n",
    "                coco.append(ooo)\n",
    "            to_corrupt.append(coco)\n",
    "\n",
    "    return to_corrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab5c266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 23004\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "with open('sentences_to_corrupt.txt', 'r') as f:\n",
    "    file = f.read()\n",
    "    split = file.split('.')\n",
    "\n",
    "proper_split_0 = []    \n",
    "for s in split:\n",
    "    if '?' in s:\n",
    "        ss = s.split('?')\n",
    "        for se in ss:\n",
    "            proper_split_0.append(se + '?')\n",
    "    else:\n",
    "        proper_split_0.append(s)\n",
    "\n",
    "proper_split = []    \n",
    "for s in proper_split_0:\n",
    "    if '!' in s:\n",
    "        ss = s.split('!')\n",
    "        for se in ss:\n",
    "            proper_split.append(se + '!')\n",
    "    else:\n",
    "        proper_split.append(s)\n",
    "        \n",
    "for p in proper_split:\n",
    "    if len(p.split()) <= 2: #removing sentences of 1 or 2 words because with 1 word, no switch between 2 words can be made,\n",
    "                            #and 2 not representative enough - there's no such case in the example data\n",
    "        proper_split.remove(p)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print('Number of sentences:', len(proper_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1509e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20369\n",
      "20275\n"
     ]
    }
   ],
   "source": [
    "to_corrupt_3000 = corruptables('sentences_to_corrupt_3000.json')\n",
    "to_corrupt_4000 = corruptables('sentences_to_corrupt_4000.json')\n",
    "to_corrupt_5000 = corruptables('sentences_to_corrupt_5000.json')\n",
    "to_corrupt_6000 = corruptables('sentences_to_corrupt_6000.json')\n",
    "to_corrupt_7000 = corruptables('sentences_to_corrupt_7000.json')\n",
    "to_corrupt_8000 = corruptables('sentences_to_corrupt_8000.json')\n",
    "to_corrupt_9000 = corruptables('sentences_to_corrupt_9000.json')\n",
    "to_corrupt_10000 = corruptables('sentences_to_corrupt_10000.json')\n",
    "to_corrupt_11000 = corruptables('sentences_to_corrupt_11000.json')\n",
    "to_corrupt_12000 = corruptables('sentences_to_corrupt_12000.json')\n",
    "to_corrupt_13000 = corruptables('sentences_to_corrupt_13000.json')\n",
    "to_corrupt_14000 = corruptables('sentences_to_corrupt_14000.json')\n",
    "to_corrupt_15000 = corruptables('sentences_to_corrupt_15000.json')\n",
    "to_corrupt_16000 = corruptables('sentences_to_corrupt_16000.json')\n",
    "to_corrupt_17000 = corruptables('sentences_to_corrupt_17000.json')\n",
    "to_corrupt_18000 = corruptables('sentences_to_corrupt_18000.json')\n",
    "to_corrupt_19000 = corruptables('sentences_to_corrupt_19000.json')\n",
    "to_corrupt_20000 = corruptables('sentences_to_corrupt_20000.json')\n",
    "to_corrupt_21000 = corruptables('sentences_to_corrupt_21000.json')\n",
    "to_corrupt_22000 = corruptables('sentences_to_corrupt_22000.json')\n",
    "to_corrupt_23000 = corruptables('sentences_to_corrupt_23000.json')\n",
    "\n",
    "total = to_corrupt_3000 + to_corrupt_4000 + to_corrupt_5000 + to_corrupt_6000 + to_corrupt_7000 + to_corrupt_8000 + to_corrupt_9000 + to_corrupt_10000 + to_corrupt_11000 + to_corrupt_12000 + to_corrupt_13000 + to_corrupt_14000 + to_corrupt_15000 + to_corrupt_16000 + to_corrupt_17000 + to_corrupt_18000 + to_corrupt_19000 + to_corrupt_20000 + to_corrupt_21000 + to_corrupt_22000 + to_corrupt_23000\n",
    "\n",
    "print(len(total))\n",
    "\n",
    "def remove_duplicates(l):\n",
    "    f = []\n",
    "    for ll in l:\n",
    "        if ll not in f:\n",
    "            f.append(ll)\n",
    "    return f\n",
    "\n",
    "all_corrupt = remove_duplicates(total)\n",
    "print(len(all_corrupt))\n",
    "testy = all_corrupt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1e286d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AB_rules(sent): #sent is of type list\n",
    "    \"\"\"\n",
    "    AB (Adverb) RULES:\n",
    "        1. (og) VB - AB --> (corrupted) AB - VB \n",
    "        2. (og) AB - VB --> (corrupted) VB - AB : subordinate clauses, usually involves a SN (att)\n",
    "                                                  in a previous position, and AB is often a negation (inte)\n",
    "    \"\"\"\n",
    "    AB_corrupted = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i-1][0] == 'AB':\n",
    "                                t_copy = t.copy()\n",
    "                                ab_i = t.index(t[i-1])\n",
    "                                t_copy[ab_i], t_copy[i] = t_copy[i], t_copy[ab_i]\n",
    "                                AB_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            elif t[i+1][0] == 'AB':\n",
    "                                t_copy = t.copy()\n",
    "                                ab_i = t.index(t[i+1])\n",
    "                                t_copy[i], t_copy[ab_i] = t_copy[ab_i], t_copy[i]\n",
    "                                AB_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return AB_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0efba445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_rules(sent):\n",
    "    \"\"\"\n",
    "    NN (Noun) RULES:\n",
    "        When the verb is in a subordinate clause, and the NN does not act as the object of the VB:\n",
    "        1. (og) VB - NN --> (corrupted) NN - VB : when something comes before it, such as an AB\n",
    "        2. (og) VB - DT + NN --> (corrupted) DT + NN - VB ('+' == two word classes go together, as a pack)\n",
    "        3. (og) VB - PS + NN --> (corrupted) PS + NN - VB\n",
    "    Conditions that don't allow the previous rules to form:\n",
    "        - if NN is complemented with a subordinate clause, e.g. \"namn som inneh책ller ord fr책n naturen\"\n",
    "    \"\"\"\n",
    "    NN_corrupted = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'NN':\n",
    "                                t_copy = t.copy()\n",
    "                                nn_i = t.index(t[i+1])\n",
    "                                t_copy[i], t_copy[nn_i] = t_copy[nn_i], t_copy[i]\n",
    "                                NN_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            elif t[i+2][0] == 'NN':\n",
    "                                if t[i+1][0] == 'PS' or t[i+1][0] == 'DT': #possessive pronouns or determiners\n",
    "                                    t_copy = t.copy()\n",
    "                                    nn_i = t.index(t[i+2])\n",
    "                                    ps_or_dt_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[ps_or_dt_i], t_copy[nn_i] = t_copy[ps_or_dt_i], t_copy[nn_i], t_copy[i]\n",
    "                                    NN_corrupted.append((t_copy, t))\n",
    "                                elif t[i+1][0] == 'JJ': #adjectives \n",
    "                                    t_copy = t.copy()\n",
    "                                    nn_i = t.index(t[i+2])\n",
    "                                    jj_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[jj_i], t_copy[nn_i] = t_copy[jj_i], t_copy[nn_i], t_copy[i]\n",
    "                                    NN_corrupted.append((t_copy, t))\n",
    "                            elif t[i-1][0] == 'NN': #adjectives before\n",
    "                                if t[i-2][0] == 'JJ':\n",
    "                                    t_copy = t.copy()\n",
    "                                    nn_i = t.index(t[i-1])\n",
    "                                    jj_i = t.index(t[i-2])\n",
    "                                    t_copy[jj_i], t_copy[nn_i], t_copy[i] = t_copy[i], t_copy[jj_i], t_copy[nn_i]\n",
    "                                    NN_corrupted.append((t_copy, t))\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return NN_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68e13d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PN_rules(sent): \n",
    "    \"\"\"\n",
    "    PN (Pronoun) RULES:\n",
    "        In the beginning of sentences:\n",
    "            1. (og) (AB) VB - PN --> (corrupted) PN - VB \n",
    "            2. (og) (HA) PN - VB --> (corrupted) VB - PN\n",
    "            3. (og) (KN) VB - PN --> (corrupted) PN - VB (subordinating conjunction)\n",
    "            4. (og) VB - PN --> PN - VB : past 1st half of sentence, usually with subordinate clauses involved (om, n채r...)\n",
    "            5. (og) PN - VB --> VB - PN : very beginning of sentences (not super common)\n",
    "            6. (og) (HP) PN - VB --> VB - PN : fr책gande/relativ pron\n",
    "    \"\"\"\n",
    "    PN_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'PN':\n",
    "                                if t[i-1][0] == 'AB' or t[i-1][0] == 'KN': #limiting to cases of subordination\n",
    "                                    t_copy = t.copy()\n",
    "                                    pn_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[pn_i] = t_copy[pn_i], t_copy[i]\n",
    "                                    PN_corrupted.append((t_copy, t))\n",
    "        #                             print(t_copy, t)\n",
    "                            elif t[i-1][0] == 'PN':\n",
    "                                t_copy = t.copy()\n",
    "                                pn_i = t.index(t[i-1])\n",
    "                                t_copy[pn_i], t_copy[i] = t_copy[i], t_copy[pn_i]\n",
    "                                PN_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return PN_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "170a5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PM_rules(sent):\n",
    "    \"\"\"\n",
    "    PM (Proper Noun) RULES:\n",
    "        When the verb is in a subordinate clause, and the PM does not act as the object of the VB:\n",
    "        1. (og) VB - PM --> (corrupted) PM - VB : when something comes before it, such as an AB\n",
    "        2. (og) VB - PM + PM --> (corrupted) PM + PM - VB : the case for name + surname\n",
    "    \"\"\"\n",
    "    PM_corrupted = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'PM':\n",
    "                                if t[i+2][0] == 'PM':\n",
    "                                    t_copy = t.copy()\n",
    "                                    pm_i = t.index(t[i+1])\n",
    "                                    pm_2_i = t.index(t[i+2])\n",
    "                                    t_copy[i], t_copy[pm_i], t_copy[pm_2_i] = t_copy[pm_i], t_copy[pm_2_i], t_copy[i]\n",
    "                                    PM_corrupted.append((t_copy, t))\n",
    "                                else:\n",
    "                                    t_copy = t.copy()\n",
    "                                    pm_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[pm_i] = t_copy[pm_i], t_copy[i]\n",
    "                                    PM_corrupted.append((t_copy, t))\n",
    "            #                         print(t_copy, t)\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return PM_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d291176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9196 sentences with adverbs corrupted\n",
      "7331 sentences with nouns corrupted\n",
      "12111 sentences with pronouns corrupted\n",
      "682 sentences with proper nouns corrupted\n"
     ]
    }
   ],
   "source": [
    "corrupted_AB = AB_rules(all_corrupt)\n",
    "corrupted_NN = NN_rules(all_corrupt)\n",
    "corrupted_PN = PN_rules(all_corrupt)\n",
    "corrupted_PM = PM_rules(all_corrupt)\n",
    "print(len(corrupted_AB), 'sentences with adverbs corrupted')\n",
    "print(len(corrupted_NN), 'sentences with nouns corrupted')\n",
    "print(len(corrupted_PN), 'sentences with pronouns corrupted')\n",
    "print(len(corrupted_PM), 'sentences with proper nouns corrupted')\n",
    "# print(corrupted_PN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33941700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(a_list):\n",
    "    final = []\n",
    "    for sentence in a_list:\n",
    "        s1, s2 = sentence\n",
    "        sent1 = ''\n",
    "        sent2 = ''\n",
    "        for w_tuple in s1:\n",
    "            sent1 += w_tuple[1] + ' '\n",
    "        for w_tuple in s2:\n",
    "            sent2 += w_tuple[1] + ' '\n",
    "        final.append((sent1, sent2))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1dfd7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "corrupted_clean_AB = cleaner(corrupted_AB)\n",
    "corrupted_clean_NN = cleaner(corrupted_NN)\n",
    "corrupted_clean_PN = cleaner(corrupted_PN)\n",
    "corrupted_clean_PM = cleaner(corrupted_PM)\n",
    "\n",
    "everything = corrupted_clean_AB + corrupted_clean_NN + corrupted_clean_PN + corrupted_clean_PM\n",
    "random.shuffle(everything)\n",
    "error_label = 'S-FinV'\n",
    "\n",
    "absolutely_everything = []\n",
    "for a in everything:\n",
    "    o, c = a\n",
    "    final = (o, c, error_label)\n",
    "    absolutely_everything.append(final)\n",
    "\n",
    "with open('S_FinV_error_dataset.csv','w') as f:\n",
    "    csv_f = csv.writer(f)\n",
    "    csv_f.writerow(['Original sentence', 'Corrected sentence','Error label'])\n",
    "    csv_f.writerows(absolutely_everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5bd858e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29320\n"
     ]
    }
   ],
   "source": [
    "print(len(absolutely_everything))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
