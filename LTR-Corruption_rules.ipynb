{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e78ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read the file\n",
    "def corruptables(jsonfile):\n",
    "    to_corrupt = []\n",
    "    with open(jsonfile) as f:\n",
    "        out = [(x) for x in json.load(f)]\n",
    "        for o in out:\n",
    "            coco = []\n",
    "            for oo in o:\n",
    "                ooo = (oo[0], oo[1])\n",
    "                coco.append(ooo)\n",
    "            to_corrupt.append(coco)\n",
    "\n",
    "    return to_corrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5c266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 22761\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "with open('sentences_to_corrupt.txt', 'r') as f:\n",
    "    file = f.read()\n",
    "    split = file.split('.')\n",
    "#     split = [e + '.' for e in file.split('.') if e]\n",
    "\n",
    "proper_split_0 = []    \n",
    "for s in split:\n",
    "    if '?' in s:\n",
    "        ss = s.split('?')\n",
    "        for se in ss:\n",
    "            proper_split_0.append(se + '?')\n",
    "    else:\n",
    "        proper_split_0.append(s + '.')\n",
    "\n",
    "proper_split = []    \n",
    "for s in proper_split_0:\n",
    "    if '!' in s:\n",
    "        ss = s.split('!')\n",
    "        for se in ss:\n",
    "            proper_split.append(se + '!')\n",
    "    else:\n",
    "        proper_split.append(s)\n",
    "        \n",
    "for p in proper_split:\n",
    "    if len(p.split()) <= 3: #removing sentences of 1 or 2 words because with 1 word, no switch between 2 words can be made,\n",
    "                            #and 2 not representative enough - there's no such case in the example data\n",
    "        proper_split.remove(p)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print('Number of sentences:', len(proper_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1509e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20369\n",
      "20307\n"
     ]
    }
   ],
   "source": [
    "to_corrupt_3000 = corruptables('sentences_to_corrupt_3000.json')\n",
    "to_corrupt_4000 = corruptables('sentences_to_corrupt_4000.json')\n",
    "to_corrupt_5000 = corruptables('sentences_to_corrupt_5000.json')\n",
    "to_corrupt_6000 = corruptables('sentences_to_corrupt_6000.json')\n",
    "to_corrupt_7000 = corruptables('sentences_to_corrupt_7000.json')\n",
    "to_corrupt_8000 = corruptables('sentences_to_corrupt_8000.json')\n",
    "to_corrupt_9000 = corruptables('sentences_to_corrupt_9000.json')\n",
    "to_corrupt_10000 = corruptables('sentences_to_corrupt_10000.json')\n",
    "to_corrupt_11000 = corruptables('sentences_to_corrupt_11000.json')\n",
    "to_corrupt_12000 = corruptables('sentences_to_corrupt_12000.json')\n",
    "to_corrupt_13000 = corruptables('sentences_to_corrupt_13000.json')\n",
    "to_corrupt_14000 = corruptables('sentences_to_corrupt_14000.json')\n",
    "to_corrupt_15000 = corruptables('sentences_to_corrupt_15000.json')\n",
    "to_corrupt_16000 = corruptables('sentences_to_corrupt_16000.json')\n",
    "to_corrupt_17000 = corruptables('sentences_to_corrupt_17000.json')\n",
    "to_corrupt_18000 = corruptables('sentences_to_corrupt_18000.json')\n",
    "to_corrupt_19000 = corruptables('sentences_to_corrupt_19000.json')\n",
    "to_corrupt_20000 = corruptables('sentences_to_corrupt_20000.json')\n",
    "to_corrupt_21000 = corruptables('sentences_to_corrupt_21000.json')\n",
    "to_corrupt_22000 = corruptables('sentences_to_corrupt_22000.json')\n",
    "to_corrupt_23000 = corruptables('sentences_to_corrupt_23000.json')\n",
    "\n",
    "total = to_corrupt_3000 + to_corrupt_4000 + to_corrupt_5000 + to_corrupt_6000 + to_corrupt_7000 + to_corrupt_8000 + to_corrupt_9000 + to_corrupt_10000 + to_corrupt_11000 + to_corrupt_12000 + to_corrupt_13000 + to_corrupt_14000 + to_corrupt_15000 + to_corrupt_16000 + to_corrupt_17000 + to_corrupt_18000 + to_corrupt_19000 + to_corrupt_20000 + to_corrupt_21000 + to_corrupt_22000 + to_corrupt_23000\n",
    "\n",
    "print(len(total))\n",
    "\n",
    "# def remove_duplicates(l):\n",
    "#     f = []\n",
    "#     for ll in l:\n",
    "#         if ll not in f:\n",
    "#             f.append(ll)\n",
    "#     return f\n",
    "\n",
    "def remove_duplicates(l):\n",
    "    f = []\n",
    "    for ll in l:\n",
    "        if len(ll) > 2:\n",
    "            if ll not in f:\n",
    "                if ll[-1][0] == 'MA':\n",
    "                    f.append(ll)\n",
    "                else:\n",
    "                    ll_copy = ll.copy()\n",
    "                    ll_copy.append(('MA', '.'))\n",
    "                    f.append(ll_copy)\n",
    "        else:\n",
    "            pass\n",
    "    return f\n",
    "\n",
    "all_corrupt = remove_duplicates(total)\n",
    "print(len(all_corrupt))\n",
    "# testy = all_corrupt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1e286d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AB_rules(sent): #sent is of type list\n",
    "    \"\"\"\n",
    "    AB (Adverb) RULES:\n",
    "        1. (og) VB - AB --> (corrupted) AB - VB \n",
    "        2. (og) AB - VB --> (corrupted) VB - AB : subordinate clauses, usually involves a SN (att)\n",
    "                                                  in a previous position, and AB is often a negation (inte)\n",
    "    \"\"\"\n",
    "    AB_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i-1][0] == 'AB':\n",
    "                                t_copy = t.copy()\n",
    "                                ab_i = t.index(t[i-1])\n",
    "                                t_copy[ab_i], t_copy[i] = t_copy[i], t_copy[ab_i]\n",
    "                                AB_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            elif t[i+1][0] == 'AB':\n",
    "                                t_copy = t.copy()\n",
    "                                ab_i = t.index(t[i+1])\n",
    "                                t_copy[i], t_copy[ab_i] = t_copy[ab_i], t_copy[i]\n",
    "                                AB_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return AB_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c99fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AB_rules2(sent): #sent is of type list\n",
    "    \"\"\"\n",
    "    AB (Adverb) RULES:\n",
    "        1. (og) VB - AB --> (corrupted) AB - VB \n",
    "        2. (og) AB - VB --> (corrupted) VB - AB : subordinate clauses, usually involves a SN (att)\n",
    "                                                  in a previous position, and AB is often a negation (inte)\n",
    "    \"\"\"\n",
    "    AB_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i-1][0] == 'AB':\n",
    "                                if i-1 == 0:\n",
    "#                                     print('first index', t[i-1], t[i])\n",
    "                                    t_copy = t.copy()\n",
    "                                    ab_i = t.index(t[i-1])\n",
    "                                    t_copy[ab_i], t_copy[i] = (t_copy[i][0], t_copy[i][1].title()), (t_copy[ab_i][0], t_copy[ab_i][1].lower())\n",
    "                                    AB_corrupted.append((t_copy, t))\n",
    "                                else:\n",
    "                                    t_copy = t.copy()\n",
    "                                    ab_i = t.index(t[i-1])\n",
    "                                    t_copy[ab_i], t_copy[i] = t_copy[i], t_copy[ab_i]\n",
    "                                    AB_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            elif t[i+1][0] == 'AB':\n",
    "                                t_copy = t.copy()\n",
    "                                ab_i = t.index(t[i+1])\n",
    "                                t_copy[i], t_copy[ab_i] = t_copy[ab_i], t_copy[i]\n",
    "                                AB_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return AB_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0efba445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_rules(sent):\n",
    "    \"\"\"\n",
    "    NN (Noun) RULES:\n",
    "        When the verb is in a subordinate clause, and the NN does not act as the object of the VB:\n",
    "        1. (og) VB - NN --> (corrupted) NN - VB : when something comes before it, such as an AB\n",
    "        2. (og) VB - DT + NN --> (corrupted) DT + NN - VB ('+' == two word classes go together, as a pack)\n",
    "        3. (og) VB - PS + NN --> (corrupted) PS + NN - VB\n",
    "    Conditions that don't allow the previous rules to form:\n",
    "        - if NN is complemented with a subordinate clause, e.g. \"namn som innehåller ord från naturen\"\n",
    "    \"\"\"\n",
    "    NN_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'NN':\n",
    "                                t_copy = t.copy()\n",
    "                                nn_i = t.index(t[i+1])\n",
    "                                t_copy[i], t_copy[nn_i] = t_copy[nn_i], t_copy[i]\n",
    "                                NN_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            elif t[i+2][0] == 'NN':\n",
    "                                if t[i+1][0] == 'PS' or t[i+1][0] == 'DT': #possessive pronouns or determiners\n",
    "                                    t_copy = t.copy()\n",
    "                                    nn_i = t.index(t[i+2])\n",
    "                                    ps_or_dt_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[ps_or_dt_i], t_copy[nn_i] = t_copy[ps_or_dt_i], t_copy[nn_i], t_copy[i]\n",
    "                                    NN_corrupted.append((t_copy, t))\n",
    "                                elif t[i+1][0] == 'JJ': #adjectives \n",
    "                                    t_copy = t.copy()\n",
    "                                    nn_i = t.index(t[i+2])\n",
    "                                    jj_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[jj_i], t_copy[nn_i] = t_copy[jj_i], t_copy[nn_i], t_copy[i]\n",
    "                                    NN_corrupted.append((t_copy, t))\n",
    "                            elif t[i-1][0] == 'NN': #adjectives before\n",
    "                                if t[i-2][0] == 'JJ':\n",
    "                                    t_copy = t.copy()\n",
    "                                    nn_i = t.index(t[i-1])\n",
    "                                    jj_i = t.index(t[i-2])\n",
    "                                    t_copy[jj_i], t_copy[nn_i], t_copy[i] = t_copy[i], t_copy[jj_i], t_copy[nn_i]\n",
    "                                    NN_corrupted.append((t_copy, t))\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return NN_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f747c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_rules2(sent):\n",
    "    \"\"\"\n",
    "    NN (Noun) RULES:\n",
    "        When the verb is in a subordinate clause, and the NN does not act as the object of the VB:\n",
    "        1. (og) VB - NN --> (corrupted) NN - VB : when something comes before it, such as an AB\n",
    "        2. (og) VB - DT + NN --> (corrupted) DT + NN - VB ('+' == two word classes go together, as a pack)\n",
    "        3. (og) VB - PS + NN --> (corrupted) PS + NN - VB\n",
    "    Conditions that don't allow the previous rules to form:\n",
    "        - if NN is complemented with a subordinate clause, e.g. \"namn som innehåller ord från naturen\"\n",
    "    \"\"\"\n",
    "    NN_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'NN':\n",
    "                                if i == 0:\n",
    "                                    t_copy = t.copy()\n",
    "                                    nn_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[nn_i] = (t_copy[nn_i][0], t_copy[nn_i][1].title()), (t_copy[i][0], t_copy[i][1].lower())\n",
    "                                    NN_corrupted.append((t_copy, t))\n",
    "                                else:\n",
    "                                    t_copy = t.copy()\n",
    "                                    nn_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[nn_i] = (t_copy[nn_i][0], t_copy[nn_i][1].lower()), (t_copy[i][0], t_copy[i][1].lower())\n",
    "                                    NN_corrupted.append((t_copy, t))\n",
    "                            elif t[i+2][0] == 'NN':\n",
    "                                if i == 0:\n",
    "                                    if t[i+1][0] == 'PS' or t[i+1][0] == 'DT': #possessive pronouns or determiners\n",
    "                                        t_copy = t.copy()\n",
    "                                        nn_i = t.index(t[i+2])\n",
    "                                        ps_or_dt_i = t.index(t[i+1])\n",
    "                                        t_copy[i], t_copy[ps_or_dt_i], t_copy[nn_i] = (t_copy[ps_or_dt_i][0], t_copy[ps_or_dt_i][1].title()), t_copy[nn_i], (t_copy[i][0], t_copy[i][1].lower())\n",
    "                                        NN_corrupted.append((t_copy, t))\n",
    "                                    elif t[i+1][0] == 'JJ': #adjectives \n",
    "                                        t_copy = t.copy()\n",
    "                                        nn_i = t.index(t[i+2])\n",
    "                                        jj_i = t.index(t[i+1])\n",
    "                                        t_copy[i], t_copy[jj_i], t_copy[nn_i] = (t_copy[jj_i][0], t_copy[jj_i][1].title()), t_copy[nn_i], (t_copy[i][0], t_copy[i][1].lower())\n",
    "                                        NN_corrupted.append((t_copy, t))\n",
    "                                else:\n",
    "                                    if t[i+1][0] == 'PS' or t[i+1][0] == 'DT': #possessive pronouns or determiners\n",
    "                                        t_copy = t.copy()\n",
    "                                        nn_i = t.index(t[i+2])\n",
    "                                        ps_or_dt_i = t.index(t[i+1])\n",
    "                                        t_copy[i], t_copy[ps_or_dt_i], t_copy[nn_i] = (t_copy[ps_or_dt_i][0], t_copy[ps_or_dt_i][1].lower()), (t_copy[nn_i][0], t_copy[nn_i][1].lower()), t_copy[i]\n",
    "                                        NN_corrupted.append((t_copy, t))\n",
    "                                    elif t[i+1][0] == 'JJ': #adjectives \n",
    "                                        t_copy = t.copy()\n",
    "                                        nn_i = t.index(t[i+2])\n",
    "                                        jj_i = t.index(t[i+1])\n",
    "                                        t_copy[i], t_copy[jj_i], t_copy[nn_i] = (t_copy[jj_i][0], t_copy[jj_i][1].lower()), (t_copy[nn_i][0], t_copy[nn_i][1].lower()), t_copy[i]\n",
    "                                        NN_corrupted.append((t_copy, t))\n",
    "                            elif t[i-1][0] == 'NN': #adjectives before\n",
    "                                if t[i-2][0] == 'JJ':\n",
    "                                    if t.index(t[i-2]) == 0:\n",
    "                                        t_copy = t.copy()\n",
    "                                        nn_i = t.index(t[i-1])\n",
    "                                        jj_i = t.index(t[i-2])\n",
    "                                        t_copy[jj_i], t_copy[nn_i], t_copy[i] = (t_copy[i][0], t_copy[i][1].title()), (t_copy[jj_i][0], t_copy[jj_i][1].lower()), t_copy[nn_i]\n",
    "                                        NN_corrupted.append((t_copy, t))\n",
    "                                    else:\n",
    "                                        t_copy = t.copy()\n",
    "                                        nn_i = t.index(t[i-1])\n",
    "                                        jj_i = t.index(t[i-2])\n",
    "                                        t_copy[jj_i], t_copy[nn_i], t_copy[i] = t_copy[i], t_copy[jj_i], t_copy[nn_i]\n",
    "                                        NN_corrupted.append((t_copy, t))\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return NN_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "68e13d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PN_rules(sent): \n",
    "    \"\"\"\n",
    "    PN (Pronoun) RULES:\n",
    "        In the beginning of sentences:\n",
    "            1. (og) (AB) VB - PN --> (corrupted) PN - VB \n",
    "            2. (og) (HA) PN - VB --> (corrupted) VB - PN\n",
    "            3. (og) (KN) VB - PN --> (corrupted) PN - VB (subordinating conjunction)\n",
    "            4. (og) VB - PN --> PN - VB : past 1st half of sentence, usually with subordinate clauses involved (om, när...)\n",
    "            5. (og) PN - VB --> VB - PN : very beginning of sentences (not super common)\n",
    "            6. (og) (HP) PN - VB --> VB - PN : frågande/relativ pron\n",
    "    \"\"\"\n",
    "    PN_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'PN':\n",
    "                                if t[i-1][0] == 'AB' or t[i-1][0] == 'KN': #limiting to cases of subordination\n",
    "                                    t_copy = t.copy()\n",
    "                                    pn_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[pn_i] = t_copy[pn_i], t_copy[i]\n",
    "                                    PN_corrupted.append((t_copy, t))\n",
    "        #                             print(t_copy, t)\n",
    "                            elif t[i-1][0] == 'PN':\n",
    "                                t_copy = t.copy()\n",
    "                                pn_i = t.index(t[i-1])\n",
    "                                t_copy[pn_i], t_copy[i] = t_copy[i], t_copy[pn_i]\n",
    "                                PN_corrupted.append((t_copy, t))\n",
    "        #                         print(t_copy, t)\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return PN_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf8f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PN_rules2(sent): \n",
    "    \"\"\"\n",
    "    PN (Pronoun) RULES:\n",
    "        In the beginning of sentences:\n",
    "            1. (og) (AB) VB - PN --> (corrupted) PN - VB \n",
    "            2. (og) (HA) PN - VB --> (corrupted) VB - PN\n",
    "            3. (og) (KN) VB - PN --> (corrupted) PN - VB (subordinating conjunction)\n",
    "            4. (og) VB - PN --> PN - VB : past 1st half of sentence, usually with subordinate clauses involved (om, när...)\n",
    "            5. (og) PN - VB --> VB - PN : very beginning of sentences (not super common)\n",
    "            6. (og) (HP) PN - VB --> VB - PN : frågande/relativ pron\n",
    "    \"\"\"\n",
    "    PN_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'PN':\n",
    "                                if t[i-1][0] == 'AB' or t[i-1][0] == 'KN': #limiting to cases of subordination\n",
    "                                    t_copy = t.copy()\n",
    "                                    pn_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[pn_i] = t_copy[pn_i], t_copy[i]\n",
    "                                    PN_corrupted.append((t_copy, t))\n",
    "                            elif t[i-1][0] == 'PN':\n",
    "                                if i-1 == 0:\n",
    "                                    t_copy = t.copy()\n",
    "                                    pn_i = t.index(t[i-1])\n",
    "                                    t_copy[pn_i], t_copy[i] = (t_copy[i][0], t_copy[i][1].title()), (t_copy[pn_i][0], t_copy[pn_i][1].lower())\n",
    "                                    PN_corrupted.append((t_copy, t))\n",
    "                                else:\n",
    "                                    t_copy = t.copy()\n",
    "                                    pn_i = t.index(t[i-1])\n",
    "                                    t_copy[pn_i], t_copy[i] = t_copy[i], t_copy[pn_i]\n",
    "                                    PN_corrupted.append((t_copy, t))\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return PN_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "170a5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PM_rules(sent):\n",
    "    \"\"\"\n",
    "    PM (Proper Noun) RULES:\n",
    "        When the verb is in a subordinate clause, and the PM does not act as the object of the VB:\n",
    "        1. (og) VB - PM --> (corrupted) PM - VB : when something comes before it, such as an AB\n",
    "        2. (og) VB - PM + PM --> (corrupted) PM + PM - VB : the case for name + surname\n",
    "    \"\"\"\n",
    "    PM_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'PM':\n",
    "                                if t[i+2][0] == 'PM':\n",
    "                                    t_copy = t.copy()\n",
    "                                    pm_i = t.index(t[i+1])\n",
    "                                    pm_2_i = t.index(t[i+2])\n",
    "                                    t_copy[i], t_copy[pm_i], t_copy[pm_2_i] = t_copy[pm_i], t_copy[pm_2_i], t_copy[i]\n",
    "                                    PM_corrupted.append((t_copy, t))\n",
    "                                else:\n",
    "                                    t_copy = t.copy()\n",
    "                                    pm_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[pm_i] = t_copy[pm_i], t_copy[i]\n",
    "                                    PM_corrupted.append((t_copy, t))\n",
    "            #                         print(t_copy, t)\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return PM_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5c11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PM_rules2(sent):\n",
    "    \"\"\"\n",
    "    PM (Proper Noun) RULES:\n",
    "        When the verb is in a subordinate clause, and the PM does not act as the object of the VB:\n",
    "        1. (og) VB - PM --> (corrupted) PM - VB : when something comes before it, such as an AB\n",
    "        2. (og) VB - PM + PM --> (corrupted) PM + PM - VB : the case for name + surname\n",
    "    \"\"\"\n",
    "    PM_corrupted = []\n",
    "    trash = []\n",
    "    for t in sent:\n",
    "        for i, token in enumerate(t):\n",
    "            if token[0] == 'VB':\n",
    "                try:\n",
    "                    if t[t.index(t[i+1])][1] == ':' or t[t.index(t[i+2])][1] == ':' or t[t.index(t[i+3])][1] == ':':\n",
    "                        trash.append(i)\n",
    "                    else:\n",
    "                        try:\n",
    "                            if t[i+1][0] == 'PM':\n",
    "                                if t[i+2][0] == 'PM':\n",
    "                                    t_copy = t.copy()\n",
    "                                    pm_i = t.index(t[i+1])\n",
    "                                    pm_2_i = t.index(t[i+2])\n",
    "                                    t_copy[i], t_copy[pm_i], t_copy[pm_2_i] = t_copy[pm_i], t_copy[pm_2_i], (t_copy[i][0], t_copy[i][1].lower())\n",
    "                                    PM_corrupted.append((t_copy, t))\n",
    "                                else:\n",
    "                                    t_copy = t.copy()\n",
    "                                    pm_i = t.index(t[i+1])\n",
    "                                    t_copy[i], t_copy[pm_i] = t_copy[pm_i], (t_copy[i][0], t_copy[i][1].lower())\n",
    "                                    PM_corrupted.append((t_copy, t))\n",
    "                            else:\n",
    "                                  pass\n",
    "                        except:\n",
    "                            pass\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return PM_corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d291176e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9922 sentences with adverbs corrupted\n",
      "8041 sentences with nouns corrupted\n",
      "13049 sentences with pronouns corrupted\n",
      "776 sentences with proper nouns corrupted\n"
     ]
    }
   ],
   "source": [
    "corrupted_AB = AB_rules(all_corrupt)\n",
    "corrupted_NN = NN_rules(all_corrupt)\n",
    "corrupted_PN = PN_rules(all_corrupt)\n",
    "corrupted_PM = PM_rules(all_corrupt)\n",
    "print(len(corrupted_AB), 'sentences with adverbs corrupted')\n",
    "print(len(corrupted_NN), 'sentences with nouns corrupted')\n",
    "print(len(corrupted_PN), 'sentences with pronouns corrupted')\n",
    "print(len(corrupted_PM), 'sentences with proper nouns corrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ad7315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9922 sentences with adverbs corrupted\n",
      "8041 sentences with nouns corrupted\n",
      "13049 sentences with pronouns corrupted\n",
      "776 sentences with proper nouns corrupted\n"
     ]
    }
   ],
   "source": [
    "corrupted_AB2 = AB_rules2(all_corrupt)\n",
    "corrupted_NN2 = NN_rules2(all_corrupt)\n",
    "corrupted_PN2 = PN_rules2(all_corrupt)\n",
    "corrupted_PM2 = PM_rules2(all_corrupt)\n",
    "print(len(corrupted_AB2), 'sentences with adverbs corrupted')\n",
    "print(len(corrupted_NN2), 'sentences with nouns corrupted')\n",
    "print(len(corrupted_PN2), 'sentences with pronouns corrupted')\n",
    "print(len(corrupted_PM2), 'sentences with proper nouns corrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccb07310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('PN', 'Det'),\n",
       "  ('AB', 'fort'),\n",
       "  ('VB', 'går'),\n",
       "  ('MI', ','),\n",
       "  ('PP', 'på'),\n",
       "  ('DT', 'en'),\n",
       "  ('NN', 'natt'),\n",
       "  ('AB', 'ungefär'),\n",
       "  ('MA', '.')],\n",
       " [('PN', 'Det'),\n",
       "  ('VB', 'går'),\n",
       "  ('AB', 'fort'),\n",
       "  ('MI', ','),\n",
       "  ('PP', 'på'),\n",
       "  ('DT', 'en'),\n",
       "  ('NN', 'natt'),\n",
       "  ('AB', 'ungefär'),\n",
       "  ('MA', '.')])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_AB2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33941700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(a_list):\n",
    "    final = []\n",
    "    for sentence in a_list:\n",
    "        s1, s2 = sentence\n",
    "        sent1 = ''\n",
    "        sent2 = ''\n",
    "        for w_tuple in s1:\n",
    "            sent1 += w_tuple[1] + ' '\n",
    "        for w_tuple in s2:\n",
    "            sent2 += w_tuple[1] + ' '\n",
    "        final.append((sent1, sent2))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da0e0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(a_list):\n",
    "    train = int(len(a_list)*0.8)\n",
    "    dev = int((len(a_list) - train)/2)\n",
    "    test = int((len(a_list) - train)/2)\n",
    "\n",
    "    train_tags = ['Train'] * train\n",
    "    dev_tags = ['Dev'] * dev\n",
    "    test_tags = ['Test'] * test\n",
    "\n",
    "    tags = train_tags + dev_tags + test_tags\n",
    "    random.shuffle(tags)\n",
    "    \n",
    "    if len(a_list) > len(tags):\n",
    "        tags += ['Train']\n",
    "    \n",
    "    list_with_split = []\n",
    "    for i, a in enumerate(a_list):\n",
    "        list_with_split.append((a[0], a[1], tags[i]))\n",
    "    \n",
    "    return(list_with_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b37bdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_maker(a):\n",
    "    o, c, _ = a[0], a[1], a[2]\n",
    "    oo = o.split()\n",
    "    cc = c.split()\n",
    "    indexes = []\n",
    "    words = []\n",
    "    for i, word in enumerate(oo):\n",
    "        if cc[i] == word:\n",
    "            pass\n",
    "        else:\n",
    "            indexes.append(i)\n",
    "            words.append(word)\n",
    "            \n",
    "    new_index_o = []\n",
    "    for num in indexes:\n",
    "        n = 's' + str(num)\n",
    "        new_index_o.append(n)\n",
    "    new_index_c = []\n",
    "    indexes.reverse()\n",
    "    for num in indexes:\n",
    "        n = 't' + str(num)\n",
    "        new_index_c.append(n)\n",
    "        \n",
    "    pair = []\n",
    "    for w in words:\n",
    "        pair.append(w)\n",
    "    pair += ['-->']\n",
    "    words.reverse()\n",
    "    for w in words:\n",
    "        pair.append(w)\n",
    "        \n",
    "    return new_index_o, new_index_c, pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1dfd7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "corrupted_clean_AB2 = cleaner(corrupted_AB2)\n",
    "corrupted_clean_NN2 = cleaner(corrupted_NN2)\n",
    "corrupted_clean_PN2 = cleaner(corrupted_PN2)\n",
    "corrupted_clean_PM2 = cleaner(corrupted_PM2)\n",
    "corrupted_clean_with_tag_AB2 = splitter(corrupted_clean_AB2)\n",
    "corrupted_clean_with_tag_NN2 = splitter(corrupted_clean_NN2)\n",
    "corrupted_clean_with_tag_PN2 = splitter(corrupted_clean_PN2)\n",
    "corrupted_clean_with_tag_PM2 = splitter(corrupted_clean_PM2)\n",
    "\n",
    "# everything = corrupted_clean_AB2 + corrupted_clean_NN2 + corrupted_clean_PN2 + corrupted_clean_PM2\n",
    "everything = corrupted_clean_with_tag_AB2 + corrupted_clean_with_tag_NN2 + corrupted_clean_with_tag_PN2 + corrupted_clean_with_tag_PM2\n",
    "random.shuffle(everything)\n",
    "error_label = 'S-FinV'\n",
    "\n",
    "absolutely_everything = []\n",
    "for a in everything:\n",
    "    o, c, split = a\n",
    "    o_edges, c_edges, pair = edges_maker(a)\n",
    "    final = (o, c, o_edges, c_edges, pair, error_label, split)\n",
    "    absolutely_everything.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17d9cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('S_FinV_error_dataset_v3.csv','w') as f:\n",
    "    csv_f = csv.writer(f)\n",
    "    csv_f.writerow(['Corrupted sentence', 'Seed sentence', 'Error index corrupted', 'Error index seed', 'Confusion pairs', 'Error label', 'Split'])\n",
    "    csv_f.writerows(absolutely_everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bd858e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31788\n"
     ]
    }
   ],
   "source": [
    "print(len(absolutely_everything))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
